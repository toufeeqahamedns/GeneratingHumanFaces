# =======================================================================================
# ENCODER RELATED ARGUMENTS ... :)
# =======================================================================================

annotations_file: "/content/GeneratingHumanFaces/data/face2text_v1.0/raw.json"
# annotation file

encoder_file: "/content/GeneratingHumanFaces/data/infersent2.pkl"
# pretrained encoder file (compatible with my code)

embedding_file: "/content/GeneratingHumanFaces/data/crawl-300d-2M.vec"
# embedding file

# =======================================================================================
# AUGMENTOR RELATED ARGUMENTS ... :)
# =======================================================================================

ca_hidden_size: 4096
# output size of the pretrained encoder

ca_out_size: 256
# output size of the conditioning augmentor

compressed_latent_size: 128
# output size of the compressed latents

a_lr: 0.003
# learning rate for augmentor

# =======================================================================================
# GAN RELATED ARGUMENTS ... :)
# =======================================================================================

images_dir: "/content/GeneratingHumanFaces/data/celeba"
# path for the images directory

flip_augment: True
# whether to randomly mirror the images during training

sample_dir: "/content/GeneratingHumanFaces/samples/1/"
# path for the generated samples directory

model_dir: "/content/GeneratingHumanFaces/models/1/"
# path for saved models directory

loss_function: "relativistic-hinge-cond"
                   
depth: 7
# Depth of the GAN

latent_size: 512
# latent size for the generator

batch_size: 16
# batch_size for training

spoofing_factor: 16
# number of passes done (gradient accumulation) before making an update step

start: 1
# starting epoch number

num_epochs: 1000
# number of epochs for training

fade_in_percentage: 50
# % of epochs for fading in the new layer

feedback_factor: 10
# number of logs to generate per epoch

num_samples: 36
# number of samples to generate for creating the grid should be a square number preferably

checkpoint_factor: 10
# save model per n epochs

g_lr: 0.003
# learning rate for generator

d_lr: 0.003
# learning rate for discriminator

adam_beta1: 0
# value of beta_1 for adam optimizer

adam_beta2: 0.99
# value of beta_2 for adam optimizer

use_eql: True
# Whether to use equalized learning rate or not

use_ema: True
# Whether to use exponential moving averages or not

ema_decay: 0.999
# decay value for the ema

data_percentage: 100
# percentage of data to use

num_workers: 3
# number of parallel workers for reading files

# =======================================================================================
# FID RELATED ARGUMENTS ... :)
# =======================================================================================

log_fid_values: False
# Whether to log the fid values during training. Following args are used only if this is true

num_fid_images: 1000
# number of images used for calculating fid. Default: 1k

fid_temp_folder: "/content/GeneratingHumanFaces/fid/1/"
# folder to store the temporary generated fid images

fid_batch_size: 64
# Batch size used for the fid computation (Both image generation and fid calculation)

# ========================================================================================
