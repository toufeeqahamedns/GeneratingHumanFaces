# =======================================================================================
# ENCODER RELATED ARGUMENTS ... :)
# =======================================================================================

# annotation file
annotations_file: "/content/GeneratingHumanFaces/data/face2text_v1.0/raw.json"

# pretrained encoder file (compatible with my code)
encoder_file: "/content/GeneratingHumanFaces/data/infersent2.pkl"

# embedding file
embedding_file: "/content/GeneratingHumanFaces/data/crawl-300d-2M.vec"

# =======================================================================================
# AUGMENTOR RELATED ARGUMENTS ... :)
# =======================================================================================

# output size of the pretrained encoder
ca_hidden_size: 4096

# output size of the conditioning augmentor
ca_out_size: 256

# output size of the compressed latents
compressed_latent_size: 128

# learning rate for augmentor
a_lr: 0.003

# =======================================================================================
# GAN RELATED ARGUMENTS ... :)
# =======================================================================================

# path for the images directory
images_dir: "/content/GeneratingHumanFaces/data/celeba"

# whether to randomly mirror the images during training
flip_augment: True

# path for the generated samples directory
sample_dir: "/content/gdrive/My\ Drive/GeneratingHumanFaces/samples/1/"

# path for saved models directory
model_dir: "/content/gdrive/My\ Drive/GeneratingHumanFaces/models/1/"

loss_function: "relativistic-hinge-cond"
                   
# Depth of the GAN
depth: 7

# latent size for the generator
latent_size: 512

# batch_size for training
batch_size: 14

# number of passes done (gradient accumulation) before making an update step
spoofing_factor: 16

# starting epoch number
start: 1

# number of epochs for training
num_epochs: 1000

# % of epochs for fading in the new layer
fade_in_percentage: 50

# number of logs to generate per epoch
feedback_factor: 10

# number of samples to generate for creating the grid should be a square number preferably
num_samples: 36

# save model per n epochs
checkpoint_factor: 10

# learning rate for generator
g_lr: 0.003

# learning rate for discriminator
d_lr: 0.003

# value of beta_1 for adam optimizer
adam_beta1: 0

# value of beta_2 for adam optimizer
adam_beta2: 0.99

# Whether to use equalized learning rate or not
use_eql: True

# Whether to use exponential moving averages or not
use_ema: True

# decay value for the ema
ema_decay: 0.999

# percentage of data to use
data_percentage: 100

# number of parallel workers for reading files
num_workers: 3

# =======================================================================================
# FID RELATED ARGUMENTS ... :)
# =======================================================================================

# Whether to log the fid values during training. Following args are used only if this is true
log_fid_values: False

# number of images used for calculating fid. Default: 1k
num_fid_images: 1000

# folder to store the temporary generated fid images
fid_temp_folder: "/content/gdrive/My\ Drive/GeneratingHumanFaces/fid/1/"

# Batch size used for the fid computation (Both image generation and fid calculation)
fid_batch_size: 64

# ========================================================================================
